{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/data/schoiaj/repos/nli_explain')\n",
    "\n",
    "import torch\n",
    "from explainers.naive_explain.naive_explainer import NaiveExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "explainer = NaiveExplainer('bert-base-uncased', device=device, baseline_token='[MASK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contradiction example\n",
    "# premise = \"I didn't think that the movie was that great.\"\n",
    "# hypothesis = \"The movie was excellent.\"\n",
    "# [(didn't + great <-> excellent)]\n",
    "\n",
    "# entailment example\n",
    "# premise = 'At the other end of Pennsylvania Avenue, people began to line up for a White House tour.'\t\n",
    "# hypothesis = 'People formed a line at the end of Pennsylvania Avenue.'\n",
    "# [(began to line up <-> formed a line)]\n",
    "\n",
    "# neutral example\n",
    "premise = \"Your gift is appreciated by each and every student who will benefit from your generosity.\"\t\n",
    "hypothesis = \"Hundreds of students will benefit from your generosity.\"\n",
    "# [each and every <-> Hundreds of]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premise: Your gift is appreciated by each and every student who will benefit from your generosity.\n",
      "hypothesis: Hundreds of students will benefit from your generosity.\n",
      "\n",
      "original prediction was entailment / with confidence: 0.6256911158561707\n",
      "\n",
      "1. ('Your gift is appreciated by each and every student who will benefit from your [MASK]', 'Hundreds of [MASK] will benefit from your generosity.') | -0.0004000663757324219\n",
      "2. ('Your gift is appreciated by each and every student who will benefit from your [MASK]', '[MASK] of students will benefit from your generosity.') | --0.0018377900123596191\n",
      "3. ('Your gift is appreciated by each and every student who will benefit from your [MASK]', 'Hundreds of students will [MASK] from your generosity.') | --0.0020561814308166504\n",
      "4. ('Your [MASK] is appreciated by each and every student who will benefit from your generosity.', 'Hundreds of students will [MASK] from your generosity.') | --0.0024448633193969727\n",
      "5. ('Your gift is appreciated by each and every student who will benefit from your [MASK]', 'Hundreds of students will benefit from your [MASK]') | --0.002530217170715332\n",
      "6. ('Your [MASK] is appreciated by each and every student who will benefit from your generosity.', '[MASK] of students will benefit from your generosity.') | --0.002672135829925537\n",
      "7. ('Your gift is [MASK] by each and every student who will benefit from your generosity.', 'Hundreds of students will [MASK] from your generosity.') | --0.003589034080505371\n",
      "8. ('Your gift is [MASK] by each and every student who will benefit from your generosity.', '[MASK] of students will benefit from your generosity.') | --0.004055380821228027\n",
      "9. ('Your [MASK] is appreciated by each and every student who will benefit from your generosity.', 'Hundreds of [MASK] will benefit from your generosity.') | --0.004393935203552246\n",
      "10. ('Your gift is appreciated by each and [MASK] student who will benefit from your generosity.', '[MASK] of students will benefit from your generosity.') | --0.004654407501220703\n",
      "11. ('Your [MASK] is appreciated by each and every student who will benefit from your generosity.', 'Hundreds of students will benefit from your [MASK]') | --0.004701793193817139\n",
      "12. ('Your gift is [MASK] by each and every student who will benefit from your generosity.', 'Hundreds of students will benefit from your [MASK]') | --0.004817843437194824\n",
      "13. ('Your gift is appreciated by each and [MASK] student who will benefit from your generosity.', 'Hundreds of students will [MASK] from your generosity.') | --0.004860639572143555\n",
      "14. ('Your gift is [MASK] by each and every student who will benefit from your generosity.', 'Hundreds of [MASK] will benefit from your generosity.') | --0.004937529563903809\n",
      "15. ('Your gift is appreciated by each and [MASK] student who will benefit from your generosity.', 'Hundreds of [MASK] will benefit from your generosity.') | --0.005441248416900635\n",
      "16. ('Your gift is appreciated by each and [MASK] student who will benefit from your generosity.', 'Hundreds of students will benefit from your [MASK]') | --0.006182253360748291\n",
      "\n",
      "premise: {'appreciated', 'generosity.', 'every', 'gift'} \n",
      "hypothesis: {'Hundreds', 'benefit', 'students', 'generosity.'}\n"
     ]
    }
   ],
   "source": [
    "explanation, tokens, pred_class, orig_confidence = explainer.explain(premise, hypothesis, topk=None, return_cache=True)\n",
    "# explainer.analyze_result(premise, hypothesis, pred_class, orig_confidence, attributions, top_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c2746b4c817b2e7822e65c51ec19822c8b0676bc7037025bbef03eb15b20d6a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('synch': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
